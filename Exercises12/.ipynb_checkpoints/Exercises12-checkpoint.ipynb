{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio di Simulazione Numerica\n",
    "## Esercitazione 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Esercizio 12.1\n",
    "In questo esercizio vogliamo usare una rete neurale DNN (Deep Neural Network) di tipo sequenziale per riconoscere le cifre da 0 a 9 scritte a mano. Come dati per il training della rete neurale sfruttiamo il dataset MNIST contenente 70000 cifre scritte a mano in formato griglia da 28x28 pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice per creare questa rete neurale è quello fornito dal professore durante le lezioni, in cui si usa una architettura sequenziale formata da:\n",
    "- Un lyer di input con 784 (28x28) unità, che ricesve in ingresse dei valori compresi fra 0 e 1 che indicano la gradazione in scala di grigi del pixel.\n",
    "- Due layer nascosti, il primo di 400 unità e il secondo di 100 unità, entrambi con funzione di attivazione Relu\n",
    "- Per il processo di training a ogni epche viene applicato un Dropout di $0.5$\n",
    "- Infine si ha il layer di output costituito da 10 unità, corrispondente alle 10 cifre da riconoscere. La funzione di attivazione per quest'ultimo lay è la Softmax, in modo che gli output siano valori fra 0 e 1. Infatti questo questo è un problema di classificazione.\n",
    "I dati sono divisi in 60000 dati di training e 10000 di validazione e il processo di treining procede per 5 epoche.\n",
    "Il codice per questo esercizio si trova nella directory *DNN*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice fornito ha già una buona efficentza, avendo una accuratezza del 95%. Vogliamo però studiare come cambiano le performance della rete neurale se usiamo diversi tipi di algoritmi di ottimizzazione, mantenendo inalterati tutti gli altri parametri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottimizzatore 1 - SGD 1\n",
    "In questo caso utlizziamo come ottimizzatore lo Stochastic Gradient Descent, in cui i paramentri dell'algritmo sono quelli di default di Keras, cioé\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)</font>\n",
    "</p>\n",
    "Di segutio sono riportati i grafici che rappresentano l'evoluzione dell'accuratezza e del costo durante il processo di training per i dati di validazione e di training.\n",
    "\n",
    "<img src=\"DNN/SGD_1/loss.png\" width=\"640\">\n",
    "<img src=\"DNN/SGD_1/accuracy.png\" width=\"640\">\n",
    "\n",
    "Alla fine del training si ha:\n",
    "- Test loss: 0.1572\n",
    "- Test accuracy: 0.9501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottimizzatore 2 - SGD 2\n",
    "In questo caso utlizziamo come ottimizzatore lo Stochastic Gradient Descent, però modifichiamo i parametri dell'algoritmo,in particolare introduciamo l'uso del momento (che permette di tenere traccia dell'evoluazione precedente dell'algoritmo) applicando il momento di Nestorov e introducendo ancche il decadimento del learning rate.\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)</font>\n",
    "</p>\n",
    "Di segutio sono riportati i grafici che rappresentano l'evoluzione dell'accuratezza e del costo durante il processo di training per i dati di validazione e di training.\n",
    "\n",
    "<img src=\"DNN/SGD_2/loss.png\" width=\"640\">\n",
    "<img src=\"DNN/SGD_2/accuracy.png\" width=\"640\">\n",
    "\n",
    "Alla fine del training si ha:\n",
    "- Test loss: 0.06889\n",
    "- Test accuracy: 0.9786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottimizzatore 3 - Adagrad\n",
    "In questo caso utlizziamo come ottimizzatore l'Adagrad', in cui i learning rates cambiano per i vari paramentri in base a quanto sono già stati aggiornati, tenendo conto di tutti i gradienti precedenti.\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">optimizer=Adagrad(lr=0.02, epsilon=1e-7, decay=1e-6)</font>\n",
    "</p>\n",
    "Di segutio sono riportati i grafici che rappresentano l'evoluzione dell'accuratezza e del costo durante il processo di training per i dati di validazione e di training.\n",
    "\n",
    "<img src=\"DNN/Adagrad/loss.png\" width=\"640\">\n",
    "<img src=\"DNN/Adagrad/accuracy.png\" width=\"640\">\n",
    "\n",
    "Alla fine del training si ha:\n",
    "- Test loss: 0.0818\n",
    "- Test accuracy: 0.9735"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottimizzatore 4 - Adadelta\n",
    "In questo caso utlizziamo come ottimizzatore l'Adadelta', simile all'Adagrad ma in cui si tiene conto slo di un certo numero di gradienti calcolati precedentemente e non tutti quanti.\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">optimizer=Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)</font>\n",
    "</p>\n",
    "Di segutio sono riportati i grafici che rappresentano l'evoluzione dell'accuratezza e del costo durante il processo di training per i dati di validazione e di training.\n",
    "\n",
    "<img src=\"DNN/Adadelta/loss.png\" width=\"640\">\n",
    "<img src=\"DNN/Adadelta/accuracy.png\" width=\"640\">\n",
    "\n",
    "Alla fine del training si ha:\n",
    "- Test loss: 0.08217\n",
    "- Test accuracy: 0.9781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generale, rispetto allo Stochastic Gradient Descent, l'introduzione di nuovi elementi all'algoritmo di ottimaizzazione ne ha migliorato l'efficienza. In particolare, rispetto a quelli provati, nel processo di ottimizzazione è utile introdurre un elemento di memoria delle modifiche precedenti, come accade per il momento nello SGD o per gli Adadelta e Adagrad. Inoltre il fatto che, guardando i risultati riportati sopra, gli algoritmi che portanoa una maggior accuratezza sono lo SGD con momento e l'Adadelta (mentre l'Adagrad ha una accuratezza finale di poco più piccola) fa intuire che è meglio avere un elemento di meoria a a breve termine, per non tenere conto di proprio tutte le modifiche apportate precedentemente ai paramentri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 12.2\n",
    "In questo esercizio vogliamo ancora usare una rete neurale per riconoscere delle cife scritte a mano, però ora vogliamo costruire una Rete Neurale Convoluzionale. In particolare facciamo uso dei layer di keras **Conv2D** e **MaxPooling2d** che permettono di eseeguire una convoluzione dell'input tramite una serie di filtri e successivamente eseguire un coarse-grain dei dati filtrati.\n",
    "Diccome i dati sono sempre delle grigle 28x28 in scala di grigi, la profondità (numero di canali) dei layer convoluzionale è 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per quanto detto l'unica cosa da modificare rispetto al codice per la DNN è l'architettura della rete neurale, modificando i vari layer in modo da avere dei layer convoluzionali sguiti da dei layer di pooling. Siccome però l'output deve comunque essere un vettore da 10 componenti (normalizzato sempre con la funzione Softmax) a un certo punto bisogna anche introdurre un layer con la classe **Flatten** in modo datrasformare gli output delle varie griglie ottenute con i vari filtri dei layer convoluazionali in dati vettoriali da usare con dei layer di tipo **Dense**.\n",
    "Il codice per questo esercizio si trova nella directory *CNN*.\n",
    "Come ottimizzatore si usa lo Stochastic Gradient Descent, in particolare con i parametri configurate come nel secondo esempio dell'esercizio precedente:\n",
    "\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'architettura utilizzata  per questa Rete Neurale Convoluzionale è specificata nel codice dai seguenti layer:\n",
    "\n",
    "<p style=\"border:2px; border-style:solid; border-color:#F5F5F5; padding: 1em; background-color:#F5F5F5\">\n",
    "<font face=\"Courier\">\n",
    "model = Sequential() <br>\n",
    "\tmodel.add(Conv2D(6, kernel_size=(5, 5),\tactivation='relu', input_shape=input_shape))<br>\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))<br>\n",
    "\tmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=input_shape)<br>\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))<br>\n",
    "\tmodel.add(Flatten())<br>\n",
    "\tmodel.add(Dense(60, activation='relu'))<br>\n",
    "\tmodel.add(Dense(50, activation='relu'))<br>\n",
    "\tmodel.add(Dropout(0.5))<br>\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "</font>\n",
    "</p>\n",
    "Quindi con due layer convoluazionali seguiti dai rispettivi layer di pooling e con due layer densamente connessi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per l'analisi della performance della Rete Neurale consideriamo sempre i valori di Costo e Accuratezza, guardando sempre il loro andamento in funzione del numero di epoche.\n",
    "\n",
    "<img src=\"CNN/loss.png\" width=\"640\">\n",
    "<img src=\"CNN/accuracy.png\" width=\"640\">\n",
    "\n",
    "Alla fine del training si ha:\n",
    "- Test loss: 0.04192\n",
    "- Test accuracy: 0.9886\n",
    "\n",
    "Vediamo che l'accuratezza è di circa il 99%, chiaramente migliore di tutti glie esempi dell'esercizio precedente con la DNN\n",
    "\n",
    "Di seguito sono riportati degli esempi di predizione della Rete Neurale su alcuni campioni del set di validazione:\n",
    "\n",
    "<img src=\"CNN/prediction.png\" width=\"1080\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 12.3\n",
    "In questo esercizio vogliamo vedere l'effettiva capacita di predizione della Rete Neurale che abbiamo costruito per leggere delle cifre scritte da noi. La rete neurale dell'esercizio precedente è stata salvata nella directory *CNN/Saved*, per cui serve solo recuperarla per poi testarla sui numeri che le forniamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b1f76094e99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Digit: {}\\nPredicted: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "X_test = np.zeros((10,28,28))\n",
    "\n",
    "for i in range(10):\n",
    "    digit_filename = \"./Numbers/num\" + str(i) + \".png\"\n",
    "    digit_in = Image.open(digit_filename).convert('L')\n",
    "    ydim, xdim = digit_in.size\n",
    "    pix=digit_in.load();\n",
    "    data = np.zeros((xdim, ydim))\n",
    "    for j in range(ydim):\n",
    "        for k in range(xdim):\n",
    "            data[k,j]=pix[j,k]\n",
    "    X_test[i] = data\n",
    "\n",
    "X_test /= 255\n",
    "\n",
    "save_model_path='./CNN/Saved/.'\n",
    "model_CNN = tf.keras.models.load_model(filepath=save_model_path)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "predictions = model_CNN.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(20):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted: {}\".format(i, np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
