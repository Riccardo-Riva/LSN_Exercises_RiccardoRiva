{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio di Simulazione Numerica\n",
    "## esercitazione 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 11.1\n",
    "In questo esercizio vogliamo modificare il codice per eseguire un fit lineare tarmite Rete Neurale (NN) Feed-Forward fornito a lezione per stabilire come lavora il codice di Supervised Machine Learning con diversi valori di: numero di dati, numero di epoche e rumore dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo è eseguire un fit lineare di dati che seguono il modello\n",
    "$$\n",
    "f(x) = 2x + 1\n",
    "$$\n",
    "per $x \\in [-1,1]$,\n",
    "a cui però viene aggiunto un rumore gaussiano a media nulla e con deviazione standard $\\sigma$.\n",
    "In questo caso come rete neurale basta prendere una rete formata da un solo neurone di input e un solo neurone di output. Il neurone di output infatti riceve in input un valore reale $x$ e lo moltiplica per un certo peso $w$ e somma un bias $b$. Se come funzione di attivazione del neurone di output consideriamo l'identià, allora effettivamente la rete neurale descrive bene un modello lineare $y = w x + b$.\n",
    "Con lo Stochastic Gradient descent minimizziamo la funzione costo data dal Mean Square Error per vedere di quanto la rete neurale si avvicina al modello idelae.\n",
    "Per controllare il funzionamento della rete neurale Osserviamo i grafici che rappresentano il costo (di validazione e di training) e il confronto fra il modello e i dati predetti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 1\n",
    "\n",
    "In questo caso vogliamo prendere in considerazione un numero elevato di dati di training:\n",
    "\n",
    "- **Numero di dati per il training:** 1000\n",
    "(Come numero di dati di Validazione prendiamo $1/10$ di quelli di training).\n",
    "- **Numero di epoche:** 30\n",
    "- **Sigma = 0.2**\n",
    "\n",
    "<img src=\"linear_fit/n_train/validation_data.png\" width=\"640\">\n",
    "<img src=\"linear_fit/n_train/loss.png\" width=\"640\">\n",
    "<img src=\"linear_fit/n_train/prediction.png\" width=\"640\">\n",
    "\n",
    "Stime dei paramatri e valore della funzione costo alla fine del training:\n",
    "- m = 2.0011144\n",
    "- q = 1.002664\n",
    "- Test loss: 0.03285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 2\n",
    "\n",
    "In questo caso vogliamo prendere in considerazione un numero elevato di epoche:\n",
    "\n",
    "- **Numero di dati per il training:** 100\n",
    "- **Numero di epoche:** 200\n",
    "- **Sigma = 0.2**\n",
    "\n",
    "<img src=\"linear_fit/n_epoch/validation_data.png\" width=\"640\">\n",
    "<img src=\"linear_fit/n_epoch/loss.png\" width=\"640\">\n",
    "<img src=\"linear_fit/n_epoch/prediction.png\" width=\"640\">\n",
    "\n",
    "Stime dei paramatri e valore della funzione costo alla fine del training:\n",
    "- m = 2.0385277\n",
    "- q = 1.0235584\n",
    "- Test loss: 0.03237"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 3\n",
    "\n",
    "In questo caso vogliamo vedere se la rete neurale riesce a gestire dati molto rumorosi, con una $\\sigma$ elevata:\n",
    "\n",
    "- **Numero di dati per il training:** 1000\n",
    "- **Numero di epoche:** 50\n",
    "- **Sigma = 0.6**\n",
    "\n",
    "<img src=\"linear_fit/sigma/validation_data.png\" width=\"640\">\n",
    "<img src=\"linear_fit/sigma/loss.png\" width=\"640\">\n",
    "<img src=\"linear_fit/sigma/prediction.png\" width=\"640\">\n",
    "\n",
    "Stime dei paramatri e valore della funzione costo alla fine del training:\n",
    "- m = 2.0041554\n",
    "- q = 1.0126637\n",
    "- Test loss: 0.2955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In genrale vediamo che, in questo particolare problema, sia aumentare il numero di dati di training che aumentare il numero di epoche migliorano il training della rete neurale. Questo effettivamente è un problema semplice con un solo neurone per cui tendenzialmente non si incorre nel problema di overfitting. Chiaramente il modo più efficace per per migliorare la rete neurale è aumentare il numero di dati di training. Questo lo si vede anche se aumentiamo il valore di $\\sigma$. Infatti nel primo e nel terzo caso si ottengono dei valori di $m$ e $q$ più vicini ai valori veri rispetto al secondo caso, in cui abbiamo molti meno dati di input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 11.2\n",
    "\n",
    "In questo esercizio vogliamo eseguire un fit di una funzione polinomiale\n",
    "$$\n",
    "f(x)=4-3x-2x^2+3x^3\n",
    "$$\n",
    "per $x \\in [-1,1]$.\n",
    "Il codice rimane praticamente identico a quello precedente. L'unica cosa che cambia e a cui poiniamo più attenzione in questo caso è il numero di layer della rete neurale e il numero di unità per ogni layer, oltre che alle funzioni di attivazione dei vari neuroni. Chiaramente essendo ora la funzione da fittare più articolata di una semplice funzione lineare, ci interessa avere una rete neurale un pò più complessa, in grado di descrivere vari tipi di funzioni.\n",
    "Consideriamo tre differenti configurazioni dei layer, e studiamo come sempre il grafico di confronto fra il modello e la predizione della Rete Neurale. In generale cerchiamo di fare in modo che il numero totale di parametri sia lo stesso per tutti e tre i casi, per vedere quale struttura è più efficiente. Anche il numero di parametri e la deviazione standard del rumore rimangono gli stessi in tutti e tre i casi.\n",
    "- **Numero di dati di training:** 5000 \n",
    "- $\\sigma = 0.2$\n",
    "-\n",
    "Come funzione di attivazione, per tutti i neuroni in tutti i casi viene utilizzata la Relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 1:\n",
    "In questo caso vengono usati 3 layer e il numero di unità nei vari layer è: 1, 12, 10, 8, 1. (il primo e l'ultimo numero indicano le dimensioni dell'input e dell'output). Il training viene effettuato per $60$ epoche. Il numero totale di parametri è $251$.\n",
    "\n",
    "<img src=\"polynomial_fit/NN_1/validation_data.png\" width=\"640\">\n",
    "<img src=\"polynomial_fit/NN_1/loss.png\" width=\"640\">\n",
    "<img src=\"polynomial_fit/NN_1/prediction.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 2:\n",
    "In questo caso viene usato 1 layer nascosto e il numero di unità nei vari layer è: 1, 80, 1. Vogliamo vedere cosa succede nel caso in cui abbiamo un solo layer con un numero elevato di unità. Il training viene effettuato per $180$ epoche. Il numero totale di parametri è $241$.\n",
    "\n",
    "<img src=\"polynomial_fit/NN_2/loss.png\" width=\"640\">\n",
    "<img src=\"polynomial_fit/NN_2/prediction.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione 3:\n",
    "In questo caso vengono usati layer nascosti e il numero di unità nei vari layer è: 1, 8, 7, 7, 6, 6, 1. Vogliamo vedere cosa succede aummentando la profondita della Rete Neurale ma  tenendo un numero basso  di unità in ciascun layer. Il training viene effettuato per $60$ epoche. Il numero totale di parametri è $232$.\n",
    "\n",
    "<img src=\"polynomial_fit/NN_3/loss.png\" width=\"640\">\n",
    "<img src=\"polynomial_fit/NN_3/prediction.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studiando le tre configurazioni si vede che quella meno efficiente è quella in cui usaimo un solo layer con tanti neuroni. Infatti si vedde che quà il numero di epoche necessare per il training è di $180$, mentre negli altri due casi ne bastano $60$. Nell'intervallo $[-1,1]$ in cui si hanno i dati di training, la curva di predizione rispetta bene il modello da rappresentare. Fuori dall'intervallo invece si vede che le 2 curve sono totalmente diverse (in particolare si vede che la predizione ha un comportamento definitivamente lineare, dovuto al fatto che abbiamo scelto la Relu come funzione di attivazione. In realtà in tutti e tre i casi si vede una difficoltà a rappresentare la funzione modello nella zona $[0.7,1]$ in cui la funzione cambia derivata in un intervallo molto piccolo. Questa cosa la si può capire guardando i dati di validazione per cui in quella zona, a causa del rumore, è difficile stabilire che andamento ha la funzione modello sottostante e sembra approssimativamente piatta.\n",
    "In tutti e tre i casi si osserva che il valore di convergenza della funzione costo è di circa $0.04$. Questo fatto ha senso rispetto alla nostra scelta di $\\sigma$, infatti $0.04 = \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Esercizio 11.3\n",
    " In questo esercizio vogliamo invece usare una Rete Neaurale Feed-Froword per eseguire il fit di una funzione  bivariata.\n",
    "Il modello che vogliamo rappresentare è:\n",
    "\n",
    "$$\n",
    "f(x,y) = \\sin(x^2 + y^2)\n",
    "$$\n",
    "\n",
    "nel quadrato dato dato da: $x \\in [-\\frac{3}{2},\\frac{3}{2}]$; $y \\in [-\\frac{3}{2},\\frac{3}{2}]$.\n",
    "Prendiamo sempre un rumore Gaussiano con $ \\sigma = 0.2 $\n",
    "Il codice anche qui è sostanzialmente lo stesso del primo esercizio, la differenza principale è che ora il layer di input è formato da 2 unità."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siccome il problema bidimensionalè è molto più complicato di quello monodimensionale, la Rete Neurale che utiliziamo in questo caso ha un maggior numero di neuroni in ogni layer e quindi di parametri. La configurazione scelta per la rete è quella in cui ci sono 3 layer nascosti e il numero di nodi per layer è: (2, 40, 35, 30, 1). Il numero di dati di training è $12000$ mentre quello dei dati di validazione è $1200$. Il processo di training viene eseguito per 60 epoche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vengono mostrati i grafici con i dati di validazione (confrontati col modello), l'andamento del costo durante il training, un grafico 3D in cui è rappresentato l'errore della predizione su un campione nuovo di dati, cioè la differenza fra il valore di predizione e il modello reale che vogliamo rappresentare.\n",
    "\n",
    "<img src=\"fit_2d/validation_data.png\" width=\"1080\">\n",
    "<img src=\"fit_2d/loss.png\" width=\"1080\">\n",
    "<img src=\"fit_2d/prediction_error.png\" width=\"1080\">\n",
    "<img src=\"fit_2d/xz_view.png\" width=\"1080\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando L'ultimo grafico si vede come la differenza fra il modello e la rappresentazione finale tramite rete neurale è minore di $0.1$. I punti in cui la rappresentazione peggiora sono gli angoli del quadrato. effettivamente se guardiamo l'andamento della funzione $f(x,y)$, in quegli angoli ha una caduta brusca che è possibile fittare bene solo se abbiamo una gran quantità di dati in quelle zone. Nel resto del quadrato invece possiamo dire che in generale la differenza rimanga minore di $0.05$.\n",
    "Il valore finale della funzione costo è di $0.0397$ ed compatibile con $\\sigma^2 = 0.04$ a causa del valore di $\\sigma$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
